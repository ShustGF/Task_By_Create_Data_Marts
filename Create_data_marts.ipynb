{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yF5NF94Ed4rP"
   },
   "source": [
    "Ссылка на данный блокнот: https://colab.research.google.com/drive/1Z5fVuajC1rLZQe_w2rJ2LFEzh1SV6KXq?usp=drive_link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uGqLyDZieOwB"
   },
   "source": [
    "Устанавка необходимых модулей, как и в файле \"Generation_files.ipynb\" для работы Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 156851,
     "status": "ok",
     "timestamp": 1707332782641,
     "user": {
      "displayName": "Vladimir Shustikov",
      "userId": "11277613051912811861"
     },
     "user_tz": -180
    },
    "id": "kbMp9JeNr3W3",
    "outputId": "4e3b8d99-4da1-4d4d-832f-c700cc28fb8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
    "!wget -q http://archive.apache.org/dist/spark/spark-3.1.1/spark-3.1.1-bin-hadoop3.2.tgz\n",
    "!tar xf spark-3.1.1-bin-hadoop3.2.tgz\n",
    "!pip install -q findspark\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.1-bin-hadoop3.2\"\n",
    "import findspark\n",
    "\n",
    "findspark.init()\n",
    "\n",
    "# TODO: тоже про порядок импортов, еще импортнула dataframe, чтобы в типах функций прописать\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "from google.colab import drive\n",
    "from pyspark.sql import DataFrame, SparkSession, Window\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
    "spark.conf.set(\"spark.sql.repl.eagerEval.enabled\", True)\n",
    "\n",
    "drive.mount(\"/content/gdrive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2GkBiG_fevmJ"
   },
   "source": [
    "Объявление схемы данных для дальнейшего считывания JSON файлов и составления Data Frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 283,
     "status": "ok",
     "timestamp": 1707332832555,
     "user": {
      "displayName": "Vladimir Shustikov",
      "userId": "11277613051912811861"
     },
     "user_tz": -180
    },
    "id": "A3-xk_4GtliO"
   },
   "outputs": [],
   "source": [
    "schema = T.StructType([\n",
    "    T.StructField(\"inn\", T.StringType(), True),\n",
    "    T.StructField(\n",
    "        \"raw_cookie\",\n",
    "        T.ArrayType(\n",
    "            T.MapType(\n",
    "                T.StringType(),\n",
    "                T.StringType()\n",
    "            )\n",
    "        )\n",
    "    ),\n",
    "    T.StructField(\"event_type\", T.StringType(), True),\n",
    "    T.StructField(\"event_action\", T.StringType(), True),\n",
    "    T.StructField(\"data_value\", T.StringType(), True),\n",
    "    T.StructField(\"geocountry\", T.StringType(), True),\n",
    "    T.StructField(\"city\", T.StringType(), True),\n",
    "    T.StructField(\"user_os\", T.StringType(), True),\n",
    "    T.StructField(\"systemlanguage\", T.StringType(), True),\n",
    "    T.StructField(\"geoaltitude\", T.StringType(), True),\n",
    "    T.StructField(\"meta_platform\", T.StringType(), True),\n",
    "    T.StructField(\"screensize\", T.StringType(), True),\n",
    "    T.StructField(\"timestampcolumn\", T.DateType(), True)\n",
    "])\n",
    "# TODO: конечные скобки на уровне переменной"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fdZNt2ikfsR0"
   },
   "source": [
    "Объявление обяхательных переменных, успользуемых в функциях"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 260,
     "status": "ok",
     "timestamp": 1707332834826,
     "user": {
      "displayName": "Vladimir Shustikov",
      "userId": "11277613051912811861"
     },
     "user_tz": -180
    },
    "id": "g1TscL0F9et3"
   },
   "outputs": [],
   "source": [
    "PATH_TO_FILES = \"/content/gdrive/MyDrive/data/json/\"\n",
    "DICT_MATCH_CODE = {\"IOS\": \"IDFA\", \"Android\": \"GAID\"}\n",
    "filenames = sorted(os.listdir(PATH_TO_FILES), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GZYJ6X2ifz_0"
   },
   "source": [
    "Функция считывания JSON файла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1707332835468,
     "user": {
      "displayName": "Vladimir Shustikov",
      "userId": "11277613051912811861"
     },
     "user_tz": -180
    },
    "id": "_GeutqQwGcQz"
   },
   "outputs": [],
   "source": [
    "# TODO: давай и тут во всех функциях добавим доку\n",
    "def read_file_json(file_name: str, schema_json_file: T.StructType) -> DataFrame:\n",
    "    return spark.read.format(\"json\")\n",
    "                .load(f\"{file_name}\", schema=schema_json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dwwO8L5lf9Yz"
   },
   "source": [
    "Функция объединения данных JSON файлов и удаления дубликатов в них. Удаление производится с помощью оконной функции rank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1707332836017,
     "user": {
      "displayName": "Vladimir Shustikov",
      "userId": "11277613051912811861"
     },
     "user_tz": -180
    },
    "id": "CxBuFtIaHc7c"
   },
   "outputs": [],
   "source": [
    "# TODO: тут поправила по форматированию, точки функций должны быть на одном уровне\n",
    "def union_and_dropduplicate(df1: DataFrame, df2: DataFrame) -> DataFrame:\n",
    "    return (\n",
    "        df1.union(df2)\n",
    "           .withColumn(\n",
    "               \"rank\",\n",
    "               F.rank().over(Window.partitionBy(\"inn\").orderBy(F.desc(\"timestampcolumn\")))\n",
    "           )\n",
    "           .filter(\"rank = 1\")\n",
    "           .drop(\"rank\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AkCw-nRGgYIC"
   },
   "source": [
    "Функция считывания и создания таблицы из сгенерированных файлов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1707332836307,
     "user": {
      "displayName": "Vladimir Shustikov",
      "userId": "11277613051912811861"
     },
     "user_tz": -180
    },
    "id": "KBzWZvy89hcI"
   },
   "outputs": [],
   "source": [
    "def init_data(schema_json_file: T.StructType, count: int = len(filenames)) -> DataFrame:\n",
    "    blank_df = spark.createDataFrame([], schema=schema_json_file)\n",
    "    for i in filenames[:count]:\n",
    "        json_file = read_file_json(f\"{PATH_TO_FILES}{i}\", schema_json_file)\n",
    "        blank_df = union_and_dropduplicate(blank_df, json_file)\n",
    "    return blank_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eN2jRRs3gtwS"
   },
   "source": [
    "Функция, предоставляющая возможность получить значение словоря по его ключу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "executionInfo": {
     "elapsed": 258,
     "status": "ok",
     "timestamp": 1707336170494,
     "user": {
      "displayName": "Vladimir Shustikov",
      "userId": "11277613051912811861"
     },
     "user_tz": -180
    },
    "id": "kb_4YgQt9jsv"
   },
   "outputs": [],
   "source": [
    "def search_values_from_maptype(col_name: str, key: str) -> str:\n",
    "    return F.expr(f\"filter({col_name}, x -> x.key='{key}')\")[0][\"value\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oF1bYWGUhAZr"
   },
   "source": [
    "Функция преобразования соответствия ОС. Используется в витрине \"G\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 342,
     "status": "ok",
     "timestamp": 1707332842609,
     "user": {
      "displayName": "Vladimir Shustikov",
      "userId": "11277613051912811861"
     },
     "user_tz": -180
    },
    "id": "lMNHOpT0t5Rn"
   },
   "outputs": [],
   "source": [
    "@F.udf\n",
    "def match_code(x: str) -> str:\n",
    "    return DICT_MATCH_CODE.get(x, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "idLWA8yNhUcX"
   },
   "source": [
    "Чтобы не обращаться постоянно к функции, считывание данных занесем в переменную \"initial_data_df\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "executionInfo": {
     "elapsed": 1134,
     "status": "ok",
     "timestamp": 1707334717370,
     "user": {
      "displayName": "Vladimir Shustikov",
      "userId": "11277613051912811861"
     },
     "user_tz": -180
    },
    "id": "ir-kSJHMAvvA"
   },
   "outputs": [],
   "source": [
    "# TODO: функции как глаголы, поменять initial на init, select * идет по дефолту, так никогда не пишут\n",
    "initial_data_df = init_data(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: еще есть крутая штука - кеширование. сохраняет в памяти датасет, и все считается быстрее.\n",
    "# count - чтобы запустить процесс (cache - это транфсормация, ничего не произойдет, если не запустить действие)\n",
    "# в конце нужен unpersist()\n",
    "initial_data_df.cache().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z7ivlb2b5XHa"
   },
   "source": [
    "# Создание витрины \"A\".\n",
    "В общем и целом данная витрина - это наша сгенерированная таблица, только без поля \"INN\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CSbxNorf37KO"
   },
   "outputs": [],
   "source": [
    "data_mart_a = initial_data_df.drop(\"inn\")\n",
    "data_mart_a.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4-8cEsxEfDEI"
   },
   "source": [
    "# Создание витрины \"В\".\n",
    "В данной витрине необходимо найти все \"INN\" пользователей. Для поля \"ID\" в данной витрине была примена оконная функция, с целью показать свои знания, в последующих витриниках оконных функций использовано не будет из-за ее долгой работы при сортировке данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SIpT6r7-sWd6"
   },
   "outputs": [],
   "source": [
    "# Создать цикл счтывания DF по датам. удалять дубликать на объединении дней, удалять cookie по INN\n",
    "\n",
    "# TODO: думаю, нужна просто насмотренность кода по поводу форматирования, просто пройдись по моим изменениям\n",
    "data_mart_b = initial_data_df.select(\n",
    "    F.row_number().over(Window.orderBy(F.col(\"inn\").desc())).alias(\"id\"),\n",
    "    \"inn\"\n",
    ")\n",
    "data_mart_b.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WukdhfjCf6jI"
   },
   "source": [
    "# Создание витрины \"С\"\n",
    "В данной витрине необходимо собрать куки сайта. Для это использовалась функция\n",
    "\"pyspark.sql.functions.expr\", в которую передовалось сгенирированное значение из функции \"search_values_from_cookie\". Для генерации ID используется метод \"monotonically_increasing_id\". В последующий витринах используются эти функции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PR30cADbAdVK"
   },
   "outputs": [],
   "source": [
    "# TODO: тут почему-то отступ в 2 пробела стал вместо 4, как везде\n",
    "data_mart_c = initial_data_df.select(\n",
    "    (F.monotonically_increasing_id() + 1).alias(\"id\"),\n",
    "    search_values_from_maptype(\"raw_cookie\", \"_sa_cookie_a\").alias(\"sa_cookie_a\"))\n",
    "data_mart_c.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZbuA8x8ChpS9"
   },
   "source": [
    "# Создание витрины \"D\"\n",
    "Тоже самое что и в витрине \"В\". Подразумевается что запущен файл \"Generation_files.ipynb\", который к этому моменту, должен сгенерировать дополнительные JSON файлы, которые не пересекутся с витриной \"В\" при объединении."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x4K2MsRlgPVX"
   },
   "outputs": [],
   "source": [
    "data_mart_d = initial_data_df.select(\n",
    "    (F.monotonically_increasing_id() + 1).alias(\"id\"),\n",
    "    \"inn\"\n",
    ")\n",
    "data_mart_d.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9kqFYI_AiXP7"
   },
   "source": [
    "# Создание витрины \"E\"\n",
    "Необходимо найти телефон пользователя и захешировать его алгоритмом хешировани **md5**. Делается это с помощью встроеной функции \"pyspark.sql.functions.md5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mXrVR0JEAmJl"
   },
   "outputs": [],
   "source": [
    "data_mart_e = initial_data_df.select(\n",
    "    (F.monotonically_increasing_id() + 1).alias(\"id\"),\n",
    "    F.md5(\n",
    "        search_values_from_maptype(\"raw_cookie\", \"user_phone\")\n",
    "    ).alias(\"hash_phone_md5\")\n",
    ")\n",
    "# TODO: элиасы лучше не переносить от скобочки поля или от всего поля, если помещается\n",
    "\n",
    "data_mart_e.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WRfyfn1ljACg"
   },
   "source": [
    "# Создание витрины \"F\"\n",
    "Тоже самое что и в витрине \"E\", только с полем \"user_mail\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rSbigp1cDpQJ"
   },
   "outputs": [],
   "source": [
    "data_mart_f = initial_data_df.select(\n",
    "    (F.monotonically_increasing_id() + 1).alias(\"id\"),\n",
    "    F.md5(\n",
    "        search_values_from_maptype(\"raw_cookie\", \"user_mail\")\n",
    "    ).alias(\"hash_email_md5\")\n",
    ")\n",
    "\n",
    "data_mart_f.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GLMujftXj19p"
   },
   "source": [
    "# Создание витрины \"G\"\n",
    "\n",
    "Замена значения через функцию \"match_code\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mTYoxBswyKio"
   },
   "outputs": [],
   "source": [
    "data_mart_g = initial_data_df.select(\n",
    "    (F.monotonically_increasing_id() + 1).alias(\"id\"),\n",
    "    search_values_from_maptype(\"raw_cookie\", \"user_uid\").alias(\"user_uid\"),\n",
    "    match_code(\"user_os\").alias(\"match_code\")\n",
    ")\n",
    "\n",
    "data_mart_g.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9-_9KPGXl8i1"
   },
   "source": [
    "# Создание обобщенной витрины объединяющая все предыдущие витрины\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m4T6VeL8diO6"
   },
   "outputs": [],
   "source": [
    "main_marts = (\n",
    "    data_mart_a.select(\"raw_cookie\", \"data_value\").alias(\"df_a\")\n",
    "    .join(\n",
    "        data_mart_d.alias(\"df_d\"),\n",
    "        # TODO: обычно on, how можно опустить\n",
    "        (\n",
    "            (F.md5(F.col(\"df_d.inn\")) == F.col(\"df_a.data_value\")) |\n",
    "            (F.sha2(F.col(\"df_d.inn\"), 256) == F.col(\"df_a.data_value\"))\n",
    "        # TODO: закрывающая скобка всегда на уровне открывающей\n",
    "        ),\n",
    "        \"right\"\n",
    "    )\n",
    "    .join(\n",
    "        data_mart_b.alias(\"df_b\"),\n",
    "        (\n",
    "            (F.md5(F.col(\"df_b.inn\")) == F.col(\"df_a.data_value\")) |\n",
    "            (F.sha2(F.col(\"df_b.inn\"), 256) == F.col(\"df_a.data_value\"))\n",
    "        ),\n",
    "        \"left\"\n",
    "    )\n",
    "    .join(\n",
    "        data_mart_e.alias(\"df_e\"),\n",
    "        F.md5(\n",
    "            search_values_from_maptype(\"raw_cookie\", \"user_phone\")\n",
    "        ) == F.col(\"df_e.hash_phone_md5\"),\n",
    "        \"left\"\n",
    "    )\n",
    "    .join(\n",
    "        data_mart_f.alias(\"df_f\"),\n",
    "        # TODO: когда одно условие, тогда скобочки не нужны\n",
    "        F.md5(\n",
    "            search_values_from_maptype(\"raw_cookie\", \"user_mail\")\n",
    "        ) == F.col(\"df_f.hash_email_md5\"),\n",
    "        \"left\"\n",
    "    )\n",
    "    .join(\n",
    "        data_mart_g.alias(\"df_g\"),\n",
    "        search_values_from_maptype(\"raw_cookie\", \"user_uid\") == F.col(\"df_g.user_uid\"),\n",
    "        \"left\"\n",
    "    )\n",
    "    .join(\n",
    "        data_mart_c.alias(\"df_c\"),\n",
    "        search_values_from_maptype(\"raw_cookie\", \"_sa_cookie_a\") == F.col(\"df_c.sa_cookie_a\"),\n",
    "        \"left\"\n",
    "    )\n",
    "    .select(\n",
    "        F.col(\"df_g.user_uid\"),\n",
    "        F.col(\"df_d.inn\").alias(\"inn\"),\n",
    "        F.col(\"df_a.data_value\").alias(\"inn_hash\"),\n",
    "        F.col(\"df_e.hash_phone_md5\"),\n",
    "        F.col(\"df_f.hash_email_md5\"),\n",
    "        search_values_from_maptype(\n",
    "            \"raw_cookie\",\n",
    "            \"user_phone\"\n",
    "        ).alias(\"user_phone\"),\n",
    "        search_values_from_maptype(\n",
    "            \"raw_cookie\",\n",
    "            \"user_mail\"\n",
    "        ).alias(\"user_email\"),\n",
    "        search_values_from_maptype(\n",
    "            \"raw_cookie\",\n",
    "            \"org_uid\"\n",
    "        ).alias(\"org_uid\"),\n",
    "        F.col(\"df_d.id\").alias(\"id_d\"),\n",
    "        F.col(\"df_c.id\").alias(\"id_c\"),\n",
    "        F.col(\"df_b.id\").alias(\"id_b\"),\n",
    "        F.col(\"df_e.id\").alias(\"id_e\"),\n",
    "        F.col(\"df_f.id\").alias(\"id_f\"),\n",
    "        F.col(\"df_g.id\").alias(\"id_g\"),\n",
    "        F.array(\n",
    "            search_values_from_maptype(\"raw_cookie\", \"_sa_cookie_a\"),\n",
    "            search_values_from_maptype(\"raw_cookie\", \"_fa_cookie_a\"),\n",
    "            search_values_from_maptype(\"raw_cookie\", \"_ym_cookie_c\"),\n",
    "            search_values_from_maptype(\"raw_cookie\", \"_fbp\")\n",
    "        ).alias(\"array_cookie\")\n",
    "     )\n",
    ")\n",
    "main_marts.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: тот самый unpersist - возвращаем ресурсы\n",
    "initial_data_df.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: всегда останавливаем спарк сессию\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMxSTFMRiAzxQyD03MP8eTf",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
